name: Test Suite

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main"]

jobs:
  test:
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.10", "3.11", "3.12", "3.13"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          enable-cache: true

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Download SNAP ego-facebook dataset
        run: |
          mkdir -p ~/.graphforge/datasets
          curl -L -o ~/.graphforge/datasets/snap-ego-facebook.txt.gz https://snap.stanford.edu/data/facebook_combined.txt.gz
        shell: bash

      - name: Run unit tests
        run: uv run pytest tests/unit -n auto --junitxml=test-results-unit.xml

      - name: Run integration tests
        run: uv run pytest tests/integration -n auto --junitxml=test-results-integration.xml

      - name: Upload test results to Codecov
        uses: codecov/codecov-action@v5
        if: always()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: test-results-unit.xml,test-results-integration.xml
          flags: ${{ matrix.os }}-py${{ matrix.python-version }}
          report_type: test_results
          fail_ci_if_error: false

  lint:
    name: Lint and Format Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Check code formatting
        run: uv run ruff format --check .

      - name: Lint code
        run: uv run ruff check .

  type-check:
    name: Type Checking (mypy)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run mypy type checker
        run: uv run mypy src/graphforge --strict-optional --show-error-codes

  security:
    name: Security Scanning
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run bandit security scanner
        run: uv run bandit -c pyproject.toml -r src/

  tck-regression:
    name: TCK OpenCypher Compliance
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run TCK tests (parallel)
        id: tck_tests
        continue-on-error: true
        run: |
          uv run pytest tests/tck/ -n auto -v --junitxml=test-results-tck.xml
          echo "exit_code=$?" >> $GITHUB_OUTPUT

      - name: Check for regressions
        if: always()
        run: |
          # Extract pass/fail counts from test results
          PASSED=$(grep -o 'passed' test-results-tck.xml | wc -l || echo 0)
          FAILED=$(grep -o 'failed' test-results-tck.xml | wc -l || echo 0)
          TOTAL=$((PASSED + FAILED))

          # Expected baseline: ~40% pass rate (1565 passing out of 3885)
          EXPECTED_PASS_RATE=38
          ACTUAL_PASS_RATE=$((PASSED * 100 / TOTAL))

          echo "TCK Results: $PASSED passed, $FAILED failed out of $TOTAL tests"
          echo "Pass rate: $ACTUAL_PASS_RATE% (expected: ~40%)"

          # Fail only if pass rate drops significantly (more than 5% regression)
          if [ $ACTUAL_PASS_RATE -lt $EXPECTED_PASS_RATE ]; then
            echo "⚠️  TCK regression detected: pass rate dropped below $EXPECTED_PASS_RATE%"
            exit 1
          else
            echo "✅ TCK compliance maintained (no regression)"
          fi

      - name: Upload TCK results to Codecov
        uses: codecov/codecov-action@v5
        if: always()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: test-results-tck.xml
          flags: tck-compliance
          report_type: test_results
          fail_ci_if_error: false

      - name: Upload TCK results artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: tck-test-results
          path: test-results-tck.xml

  coverage:
    name: Coverage Report
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v6

      - name: Install uv
        uses: astral-sh/setup-uv@v7

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Download SNAP ego-facebook dataset
        run: |
          mkdir -p ~/.graphforge/datasets
          curl -L -o ~/.graphforge/datasets/snap-ego-facebook.txt.gz https://snap.stanford.edu/data/facebook_combined.txt.gz
        shell: bash

      - name: Run tests with coverage
        run: uv run pytest tests/unit tests/integration -n auto --cov=src --cov-branch --cov-report=term --cov-report=html --cov-report=xml --junitxml=test-results-full.xml

      - name: Check coverage threshold
        run: |
          uv run coverage report --fail-under=85 || echo "Coverage below 85% - expected during initial development"

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage.xml
          flags: full-coverage
          name: codecov-full
          fail_ci_if_error: false

      - name: Upload test results to Codecov
        uses: codecov/codecov-action@v5
        if: always()
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: test-results-full.xml
          flags: full-suite
          report_type: test_results
          fail_ci_if_error: false

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: htmlcov/
